{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82b9480a-356d-4e98-a366-3b9bf7b0a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from modules.preprocess import *\n",
    "from modules.utils import build_dataset, text_to_word2vec, euclid_dis, contrastive_loss, calculate_accuracy, train_epoch, eval_model\n",
    "from modules.dataloader import PairedWord2VecDataset\n",
    "from modules.model import BaseNet1D, SiameseNetwork\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import random\n",
    "from modules.rnn_model import BaseNetRNN, SiameseRNN\n",
    "from modules.transformer_model import BaseNetTransformer, SiameseTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b782ffef-15ae-4e35-9350-2c085e374563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "735746ba-7fb1-4823-9fa9-3d72dda131dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xavier/anaconda3/envs/ml_env/lib/python3.12/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_net = BaseNetTransformer(embedding_dim=300, hidden_dim=64, num_layers=1, out_features=32)\n",
    "siamese_model = SiameseTransformer(base_net)\n",
    "\n",
    "model_path = \"best_model.pth\"\n",
    "checkpoint = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "state_dict = {key.replace(\"module.\", \"\"): value for key, value in checkpoint.items()}\n",
    "siamese_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a89ce628-e74b-4e00-9409-9ff8f305dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_net = siamese_model.base_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87362cb5-9a4c-4edc-9ae7-633e4200af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = torch.rand(1,300,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dc62ab-274f-4b46-9e9d-7708798423ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "261f2457-a557-4b0a-8e6c-e82b6af99ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = build_dataset(path=\"data\", num_samples=500, rnd_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "794a6a77-12fa-4530-b580-8da0a996d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = text_edit(dataset, grp_num=False, rm_newline=True, rm_punctuation=True, lowercase=True, lemmatize=False, html_=True, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "986ed933-1648-4d96-b296-df1a77953034",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [x['text'] for x in dataset.values() if x['section_1'] in ['actualites', 'sports']]\n",
    "Y = [x['section_label'] for x in dataset.values() if x['section_1'] in ['actualites', 'sports']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce106198-ad6c-4701-a74a-df6b8c5440f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f7990b7-c8a0-4979-b880-342c342ff4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'fasttext-wiki-news-subwords-300'\n",
    "word2vec_model = api.load(model_name)\n",
    "text = \"Ceci est un texte exemple\"\n",
    "vector = text_to_word2vec(text, word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbc66cc-bece-4b12-b579-09107d1fb004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23009381-db88-42f5-8a14-152687832fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PairedWord2VecDataset(X_train, Y_train, text_to_word2vec, word2vec_model, 50)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "test_dataset = PairedWord2VecDataset(X_test, Y_test, text_to_word2vec, word2vec_model, 25)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = optim.RMSprop(siamese_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bedacf7-c454-45c3-8422-fe298cc96214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "602fdb67-e511-4478-ba6d-368fcad9c506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 23.029746296314094, Validation Accuracy: 0.52\n",
      "Model saved as best model\n",
      "Epoch 1, Train Loss: 0.3612966663562335, Validation Accuracy: 0.52\n",
      "Epoch 2, Train Loss: 0.27961852573431456, Validation Accuracy: 0.52\n",
      "Epoch 3, Train Loss: 0.3258175185093513, Validation Accuracy: 0.52\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m best_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 4\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43msiamese_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     val_accuracy \u001b[38;5;241m=\u001b[39m eval_model(siamese_model, train_loader, device)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Validation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/c/Users/Xavier/Desktop/siamese_net/modules/utils.py:73\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, optimizer, device)\u001b[0m\n\u001b[1;32m     71\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data_a, data_b)  \n\u001b[1;32m     72\u001b[0m loss \u001b[38;5;241m=\u001b[39m contrastive_loss(target, output)\n\u001b[0;32m---> 73\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     75\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "best_accuracy = 0\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_epoch(siamese_model, train_loader, optimizer, device)\n",
    "    val_accuracy = eval_model(siamese_model, train_loader, device)\n",
    "    print(f\"Epoch {epoch}, Train Loss: {train_loss}, Validation Accuracy: {val_accuracy}\")\n",
    "    \n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        torch.save(siamese_model.state_dict(), 'best_model.pth')\n",
    "        print(\"Model saved as best model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad1eb1f-75c7-4caa-bdb3-6a236402e4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9ed62f-c834-4bc2-b4a3-383f8ed1f42a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4a6156-b5c0-4377-b2cd-907623e2be6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
